# -*- coding: utf-8 -*-
"""PythonCodes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dfc2AHB9bP1mNpdQpmeWyzOMRMudtFeJ

# Printing Basic Types
"""

print("Hello World!")

print("Hello World")
print("Hello from PadhAI")

print("PadhAI")
print("Padh" "AI")

print(1729) # Ramanujan's entry

print(1729 * 2)

print(55/34) # check golden ratio

print(True)

print(True or False)

print(True and False)

"""# Variable and Inputs"""

school = "PadhaAI"

print(school)

print(type(school)) # type tekk type of variable

print(id(school))  # id tells where in the memory the school object is stored

another_school = "PadhAI"

print(another_school)

print(id(another_school)) # school and another_school are stored in same id thats why its printing same id as output.

another_school = "IIT Madras"

print(another_school)

print(id(another_school))

"""# Boolean and Integer"""

r_no = 1729

print(type(r_no))

golden_ratio = 55/34

print(type(golden_ratio))

is_good = True

print(type(is_good))

my_name = input("What is your name ")

hours_per_day = input("How many hours per day do you study ")

print(my_name )

"""# String Processing"""

topic = ("Foundations of Data Science")

print(topic)

print(topic[0])

print(topic[3])

print(topic[-1]) # prints last character

print(topic[0:10]) # prints 0 to 10th character

print(topic[12:16])

print(topic.lower())  # all character converts to lower strings

print(topic.upper()) # all character convert to upper strings.

print(topic.islower()) # checks that string is lower case or in upper case.

print(topic.find("Data")) # finding particular string in the saved index.

print(topic[14])

print(topic.replace("Science", "Engineering"))  # replacing one string with other string

print(55/34)

golden_ratio = 55/34

print(type(golden_ratio))

print(golden_ratio.is_integer())     # check weather it is string or not

print(55//34 , 55/34)

print(55 % 34 )  # gives remainder by dividing...



"""# if, else, for, while loop"""

my_name = ("Amandeep")
hours_per_day = 7
if hours_per_day > 10:                                            # if else statement
    print(my_name + " you are doing well")
else:
    print(my_name + " you need to work hard")

for i in range (5):
    print(i)

for i in range (2, 5):
    print(i, i**2)

for i in range (24):
    print (i**2)

"""Fibonacci Series

"""

a = 1
b = 1
print(a)
print(b)
for i in range(10):
    temp = a + b
    a = b
    b = temp
    print (temp)

"""While Loop"""

a = 1
b = 1
print(a)
print(b)
while b < 1729:
    temp = a+b
    a=b
    b = temp
    print(temp)

"""# Functions"""

def fibonacci(pos):
    a = 1
    b = 1
    for i in range(pos):
        temp = a + b
        a = b
        b = temp
    return temp

print(fibonacci(3))

print(fibonacci(12))

for i in range (2, 20):
    ratio = fibonacci(i) / fibonacci(i-1)
    print(i, ratio)

def fibonacci_relative(pos, a, b):
    for i in range(pos):
        temp = a + b
        a=b
        b= temp
    return temp

print(fibonacci_relative(3, 34, 55))

def fibonacci_ol (pos, a =1, b = 1):
    for i in range (pos):
        temp = a +b
        a=b
        b=temp
    return temp

print(fibonacci_ol(3))

print(fibonacci_relative(3, 34, 55))



"""Recursive Function"""

def fibonacci_recursive (n, a =1, b=1):
    if n>1:
        return fibonacci_recursive(n-1, b, a+b)
    else:
        return a+b

print(fibonacci_recursive(3, 34, 55))

"""Inverse a Number"""

def input_single_float_inverse(prompt):
    user_input = input(prompt)
    output = None
    try:
        output = 1/float(user_input)
    except ValueError:
        print("Input Value must be a float \n ")
    except ZeroDivisorError:
        print("Input Value must not be Zero \n ")
    return output
val = input_single_float_inverse("Enter Number")
print(val)

"""# List

"""

course_name = "Foundations of Data Science"
words = course_name.split()
print(words)

print(words[2].lower)

print(words[2:4])

new_words = ["Machine", "Learning"]
print(type(new_words))

print(new_words[0])

bmi_record = ["Amandeep", 75, 1.73, False]
print(type(bmi_record))

for item in bmi_record:
    print(item, type(item))

bmi_record[0] = "Krishna A"

bmi_record.append("Krishna@idontknow.com")

for item in bmi_record:
    print(item, type(item))

"""List Continued"""

bmi_dataset = (
    ["Krishna", 75, 1.73, False],
    ["Bheem", 120, 1.78, True]
)

print(type(bmi_dataset[0]))

print(bmi_dataset[0])

print(bmi_dataset[0][0])

"""#Matrix

#Tuples and Sets
"""

bmi_categories = ("UnderWeight", "Normal", "Overweight", "VeryOverWeight")
print(type(bmi_categories))

print(bmi_categories[-1])

print(bmi_categories[0:2])

bmi_categories.index("Normal")

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r10
# for i in range (100000):
#     my_list=["tuples ", "are ", "faster", "than ", "list"]

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r10
# for i in range (10000000):
#     my_tuple=("tuples ", "are ", "faster", "than ", "list")

"""#Sets"""

batsmen = {"Rohit ", "Virat", "Ravindra", "Rahul", "Shikhar"}
print(type(batsmen))

print("Rohit " in batsmen)

batsmen.index("Rohit")

bowlers={"Ishant ", "Bumrah", "Shami", "Bhuvneshwar"}
print(type(bowlers))

all_rounders = batsmen.intersection(bowlers)

print(type(all_rounders))

print(all_rounders)

players = batsmen.union(bowlers)
print(type(players))

print(players)

print(players)

print(bowlers)

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r10
# my_list = list(range(10000))
# for i in range(10000):
#     b = 1947 in my_list
#

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r10
# my_tuple = tuple(range(10000))
# for i in range(10000):
#     b = 1947 in my_tuple

# Commented out IPython magic to ensure Python compatibility.
# %%timeit -n1 -r10
# my_set = set(range(10000))
# for i in range(10000):
#     b = 1947 in my_set

"""#Dictionaries

"""

bmi_dataset = [["Krishna ", 75, 1.73, False],
              ["Bheem ", 120, 1.78, True]]

bmi_record = {
    "name":"Krishna",
    "weight":75,
    "height":1.73,
    "is_overweight":False
}
print(type(bmi_record))

bmi_record["height"]

print(bmi_record)

for key in bmi_record:
    print(key, ":", bmi_record[key])

print(bmi_record.keys())

"""#list of dictionary item"""

bmi_record_1={
    "name": "Bheem",
    "weight": 125,
    "height": 1.75,
    "is_overweight": True,
    "email":"bheem@foodtruck.com"
}

print(bmi_record_1)

#Decision Thinking

#File Handling

f = open("rabindranath.txt", "r")

print(f)

output = f.read()

print(output)

f = open("rabindranath.txt", "r")

out_line = f.readline()
print(out_line)

out_line = f.readline()
print(out_line)

f = open("rabindranath.txt", "r")
out_lines = f.readlines()
print(out_lines)

f.close()

with open("rabindranath.txt", "r") as f:
    out_lines = f.readlines()
    print(out_lines)

f.close()

for line in out_lines:
    print(line)

for line in out _lines:
    print(line)

for line in out_lines:
    print(line)

#Problem 1 and 2

f = open("rabindranath.txt", "r")
lines = f.readlines()
print(lines)
f.close()

for item in lines:
    item = item.lower()

print(lines[0])

length = len(lines)
for i in range(length):
    lines[i]=lines[i].lower()

print(lines)

for i in range(length):
    lines[i]=lines[i].replace('\n', ' ')

print(lines)

chars_to_replace = ['\n', ',', '-', '"', '(', ')']
for i in range(length):
    for s in chars_to_replace:
        lines[i]=lines[i].replace(s,' ')

print(lines)

text = " ".join(lines)

print(text)

words = text.split()
print(len,(words), words)

words_freq = {}

for word in words:
    if word in words_freq:
        words_freq[word] += 1
    else:
        words_freq[word] = 1

print(words_freq)

#sorted (x.items(), ley=lamda item: item[1])

print(sorted(words_freq.items()))

print(sorted(words_freq.items(), key = lambda item: item [1]))

#sorted by words

print(sorted(words_freq.items(), key = lambda item: item [0]))

sorted_list[-10:]
with open['most_common_words.txt']:
    for item in sorted_list[-10]:
        f_out.write(item[0] + " ")

"""#Problem 3"""

print(words)

two_gram_zip = zip(words, words[1:])

for item in two_gram_zip:
    print(item)

"""#Assignment"""

v = (1, 2, 3)
u = list(v)
print(u)

m = [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
     [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]
print(m[1][1:8:2])

d = [ [1,2, 3], [4, 5, 6]]
print(d[1])

a = None
if a:
    print("Orange")
else:
    if a== False:
        print("Apple")
    else:
        print("PineApple")

a = {1, 2, 3}
b = {'1', '2', '3'}
print(a.intersection(b))

d = {1: "one", 2:"two", 3:"three", 4:"four", 5:"five"}
d[1] += "-hundred"
print(d[1])

"""#Numpy Started

#Comparing performance with lsit, etc.
"""

import numpy as np

N = 1000000

# Commented out IPython magic to ensure Python compatibility.
# 
# %%time
# list_ = list(range(N))
# for i in range(N):
#     list_[i] = list_[i] * list_[i]

# Commented out IPython magic to ensure Python compatibility.
# 
# %%time  // magic command tell us the time taken to run code..
# list_ = list(range(N))
# list_ = [item * item for item in list_]

# Commented out IPython magic to ensure Python compatibility.
# 
# %%time
# list_ = list(range(N))
# list_ = map(lambda x: x*x, list_)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# list_ = list(range(N))
# list_sum = 0;
# for item in list:
#     list_sum += item

# Commented out IPython magic to ensure Python compatibility.
# %%time
# list_ = list(range(N))
# list_sum = sum(list)

"""#numpy"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# arr = np.arange(N)
# arr = arr * arr

# Commented out IPython magic to ensure Python compatibility.
# %%time
# arr = np.arange(N)
# arr_sum = np.sum(arr)

"""#Creating np Array"""

arr = np.arange(5)

print(arr, type(arr))

arr = np.array([0,2,4,6,8,10])

print(arr, type(arr))

arr

arr.dtype #tell data type

arr.ndim #number of dimensions

arr.shape

arr.size

arr.itemsize

"""#2d Array"""

arr2d = np.array([
    [1,2,3,4],
    [5,6,7,8]
])

arr2d.shape

arr2d.ndim

arr2d.size

"""#3d Array"""

arr3d = np.array([
    [
        [1,2,3],
        [4,5,6]
    ],
    [
        [6,7,8],
        [10,11,12],
    ],
    [
        [34,56,78],
        [11,45,90]
    ]
])

arr3d.shape

arr3d

arr3d.size

"""#Other way of creating array"""

np.ones((2,2,3))  #created the array of desired size..

1729 * np.ones((2,2,3)) # scaler is broadcasting to each points...

np.zeros((2,3,4)) # makes zero everywhere

"""#Random Values/ data for simulating or paying with data.."""

#randn - gives series of number which is sampled in distribution, with mean 0 and variance 1..
np.random.randn(2,3)

# rand generated uniformaly numbers by giving user input...
np.random.rand(2,3)
# used in simulation and sampling......

# give me random integer between 0 and 100
np.random.randint(0, 100,(2,3))
# used for generating random number from desired input..

#tells the step size.. 3rd argument and generates the number from inputted values......
np.arange(7, 71, 7 )

#linspace for linear space between two streams that is 8 and 80
np.linspace(8,80,10)

# For boolean
np.array([True, False, True])

# for strings
string_arr = np.array(['1.2', '3.5', '6.7'])

#converted from string type to array type.....
arr = np.array(string_arr, dtype='float')

np.array

"""#Indexing"""

arr3d = np.array([
    [
        [1,2,3],
        [4,5,6]
    ],
    [
        [7,8,9],
        [10,11,12]
    ]
])

print(arr3d)

#[] used for indexing
arr3d[0,0,0]

arr3d[1,0,2]

#can be also indexed using variables
i = 1
j = 0
k = 2
arr3d[i,j,k]

# accessing slices of array
arr3d[0,:,:]

#accessed using slicing methods
arr3d[:,1,:]

#fancy indexing
#we want to access that values which contains only even number are--
arr3d % 2 == 0
#returns the boolean result for all even and odd number present

#embading this condition within indexing notation of that array values
arr3d[arr3d % 2 == 0]
#returns all the even numbers with proper indexing.....
#all one dimension array are printed that are even.....

arr3d[arr3d % 2 == 1]
#prints all the one dimension array are printed that are odd....

#combine condition
arr3d[(arr3d % 2 == 1) & (arr3d > 3)]

#array slicing
arr_slice = arr3d[:,:,0:2]

print(type(arr_slice))

arr_slice.shape

arr_slice[0,0,0]=1729

arr_slice

arr3d

arr_slice = np.copy(arr3d[:,:,0:2])

arr_slice[0,0,0]=1

arr_slice

arr3d

arr = np.random.randint(1,10,(5))

arr

my_indeces = [1,3,4]

arr[my_indeces]

"""#Numpy Operations on Array"""

arr1 = np.random.rand(4,5)
arr2 = np.random.rand(4,5)

arr1

arr2

# then operations can be performned.......

np.exp(arr1)

np.log(arr1)

np.log(np.exp(arr1))

np.sin(arr1)

np.tan(arr2)

np.sqrt(arr2)

# their operation are very much faster than list and tupeles.........

arr_inv = 1/ arr1

arr_inv

print(arr_inv)

#to check for infinite value for particular indice in an array.......
np.isinf(arr_inv[0,0])

np.isinf(arr_inv)
#throws all the values that are infinite or not .......

"""#Exercise on finding number of points outside n-dimensional shpere"""

ndim = 2

npoints = 1000000

#creates matrix of each time in n dimensional matrix.....
points = np.random.rand(npoints, ndim)

points[0:2,:]

dfo = np.zeros((npoints, 1))
outside_points=0

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for i in range(npoints):
#     for j in range(ndim):
#         dfo[i] += points[i, j] ** 2
#     dfo[i] = np.sqrt(dfo[i])
#     if dfo[i]>1:
#         outside_points += 1

print('Fraction of points outside is : ',outside_points/npoints)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# sq_points = points * points
# dfo = np.sum(sq_points, axis =1) #addup along each row across all column
# #across all matrix....
# outside_points = np.sum(dfo >1)
# print('Fraction of point outside is ', outside_points/npoints)

# Commented out IPython magic to ensure Python compatibility.
# #More shorter code
# %%time
# outsides_points = np.sum(np.sqrt(np.sum(points * points, axis = 1))>1)

# using function

def area_outside_square(npoints, ndim):
    points = np.random.rand(npoints, ndim)
    return np.sum(np.sqrt(np.sum(points * points, axis=1))>1)/npoints

area_outside_square(100000, 2)

for i in range(2,11):
    print(i, area_outside_square(10000, i))

"""#Broadcasting"""

arr1 = np.arange(6)

arr1.shape

arr1

#reshaping of array
arr1 = arr1.reshape((2,3))

arr1  # output throws the modified shape of array....

arr2 = np.arange(6).reshape((3,2))

arr2

arr2 = np.arange(6).reshape((3,2))

arr1+arr2

arr2[0]

arr2[0].reshape((1,2))

arr1+arr2[0].reshape((1,2))

arr2[:, 0].reshape((3,1))

arr1 + arr2[:, 0].reshape((3,1))

arr1 + 1

"""#3d array"""

arr1 = np.arange(24).reshape((2,3,4))

arr1

arr2 = np.ones((1,4))

arr1 + arr2  #(2,3,4) + (1,4)
# 4-> is already broadcasted to 4.
# 1-> is to be broadcasted to 3.
# None dimension in (0,1,4) 0-> to be broadcasted to 2

arr1 = np.arange(4)

arr2 = np.arange(5)

print(arr1.shape, arr2.shape)

arr1 +  arr2

arr1.reshape(4, 1) + arr2
# (4,1) + (5) is broadcasted ......

arr1.T
# shortcut ot use the T as transpose........

arr = np.random.rand(3,3)

arr

arr.T

"""#File Handling"""

plants_small = np.loadtxt("planet_small.txt")

#now we have to write command to skip the first row..
#that is MERCURY.......
plants_small = np.loadtxt("planet_small.txt", skiprows=1)

#now remov mass as row header
planet_small = np.loadtxt("planet_small.txt",
                          skiprows=1,
                          usecols = (1,2,3,4,5,6,7,8,9))

planet_small

planet_small.shape

#now load the another bigger file, which have the Big amount of Data
planet = np.loadtxt("planet.txt",
                    skiprows=1,
                    usecols=(1,2,3,4,5,6,7,8,9))

#again it throws the error with "UNKNOWN" string
#genfromtxt -> generate from text
planet = np.genfromtxt("planet.txt",
                       skip_header=1,
                       usecols=[1,2,3,4,5,6,7,8,9])
#replaces "UNKNOWN" with nan keyword in output

planet

planet.shape

np.isnan(planet)

#replaces unkown data with -1 and reflects more precise data...
#in output where -1 is thrown that data is unknown to us...
planet_new = np.nan_to_num(planet, nan=-1)

planet_new

np.savetxt('planets_new.txt', planet_new,
           delimiter=',')
#new file is created with name planets_new.txt and all the
#modifications can be seen in the new file ...........

#now to save the file into non-human redable file and can be
#used only by the numpy, when required ..........
np.save("planet_new", planet_new)
#no extension .txt is need while saving file for numpy use beacause
#the numpy uses its own extension while saving .....
#result the binary file is created......

!ls  #show all the file in current directory.....

!ls -lh # now more details are shown ...

#Way of storing the multiple lines in single file .......
arr1 = np.random.rand(1000, 10)
arr2 = np.random.rand(2000, 5)
arr3 = np.random.rand(20, 10000)

#does not need extension.....
np.savez("many_arrs", arr1, arr2, arr3)

!ls -l #many_arrs.npz file is created with inputted data....

#how to load data from multiple files of arrays....
arrs = np.load('many_arrs.npz')

print(type(arrs))

arrs.files

arrs['arr_0'].shape

"""Compressing Data using NUMPY!"""

np.savez_compressed('many_arrs_compressed',
                    arr1,arr2,arr3)

!ls -lh # we can see that previous data was 1.7M
#and changed to 1.6 M.....
#Not much but some ..........

arr1 = np.zeros((10000, 10000))

np.savez("zeros", arr1)

np.savez_compressed("zeros_compressed", arr1)

!ls -lh #not much compressed but something is compressed.....

"""#Stats with Numpy"""

import numpy as np

arr = np.random.rand(100000, )

np.amin(arr) # compute the minimum value.....

np.amax(arr) #computes maximum value...

np.mean(arr) # computes mean

np.var(arr) #computes the variance ......

np.std(arr) #computes the standard deviation

np.median(arr) # computes median

np.percentile(arr, 50)  #computes the percentile

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # To compute the inter-quartile range .....
# iqr = np.percentile(arr,75) - np.percentile(arr,25)

print(arr)

print(iqr)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #fewer numpy calls & more efficient calls.......
# quartiles = np.percentile(arr,[25, 75])
# iqr = quartiles[1]-quartiles[0]

print(quartiles) # prints the quartiles of 25 and 75....

iqr = quartiles[1]-quartiles[0]

print(iqr)

"""Z-Score - which tell how far war a particular point is from mean given by distances of standard deviation..
Z-Score are -ve, if point is left of mean and +ve, is the point is right to the mean....
"""

(arr - np.mean(arr))/ np.std(arr)

"""Numerical representation of Histogram......."""

np.histogram(arr)
#Second array gives the bins of histogram ....
#Number of points within the array is given by the first array...
# 10 Bins.

#Want only 5 bins .......
np.histogram(arr,bins=5)
#now only 5 bins are printed......

# custom bins can also be given tp throw result as per user...
np.histogram(arr,bins=[0,0.25,0.5,0.75,1])
# custom bins are thrown in result........

"""Mapping points to bin"""

bins = [0, 0.25, 0.5, 0.75, 1]

np.digitize(arr,bins)

arr1 = np.random.randint(0,10, (10))
#(0,10,(10)) means 0 to 10 and upto 10 points...

arr1

bins = [0,6,10]
#includes the left point but excludes the right point....

np.digitize(arr1, bins)

np.digitize(arr1, bins, right=True)
# to avoid include and exclude points.......

"""Now, applying on Multi-dimensional array"""

arr1 = np.random.randint(50,80,100) # weight of person
#(50, 80, 100 ) -> means it is creating 100 integers between
# 50 and 80............

arr2 = np.random.randint(150,185,100)#height of person

arr3 = np.random.randint(17,22,100) #age of person

#bringing all the array all togather......
#concatinate function is used...........
np.concatenate((arr1,arr2,arr3))

np.concatenate((arr1, arr2, arr3)).shape
#tells the size of the elements that are present .......

"""vstack -> vertically stacks up arrays."""

np.vstack((arr1,arr2,arr3))

np.vstack((arr1,arr2,arr3)).shape

arr2d = np.vstack((arr1,arr2,arr3)).shape

np.amin(arr2d) # prints the smallest number in the matrix...

np.mean(arr2d, axis=1)

np.amin(arr2d, axis=1)



"""#Checking Stats rules with Numpy

Mean Subtracted array has Zero Mean
"""

arr = np.random.rand(1000)

mean = np.mean(arr)

arr1 = arr - mean

np.mean(arr1)

"""Computing mean with the smaller set of values.....

"""

arr = np.random.rand(1000)

for k in range (1,1000):
    arr1 = arr[0:k]
    print(k, np.mean(arr1))

##np.cumsum?

np.cumsum(arr)

np.cumsum(arr)/np.arange(1,1001)
#calculates the mean from 1 to 1001 number of integer...

"""Effect of Outliers on meand and median..."""

#If you add extreme values to your data then how does
# it effects the mean and median of data......

arr = np.random.randint(1,100,100)
np.mean(arr)

np.median(arr)

#now adding the outliers .....
arr = np.append(arr, [1000,2000])

arr.shape

np.mean(arr) # mean changed much....

np.median(arr) # median does not changed much....

"""effect of scaling arrays on mean and median"""

arr = np.random.rand(100)

np.mean(arr)

np.median(arr)

arr1 = 2.5 * arr + 0.655

print(np.mean(2.5 * arr1 + 0.655),
      2.5 * np.mean(arr) + 0.655)

print(np.median(2.5 * arr1 + 0.655),
      2.5 * np.median(arr) + 0.655)

print(np.var(2.5 * arr1 + 0.655),
      2.5 * np.var(arr) + 0.655)

print(np.std(2.5 * arr1 + 0.655),
      2.5 * np.std(arr) + 0.655)

"""#Case Study"""

import numpy as np

#! head is magic commands that print first few lines of data from file.
!head cric_data.tsv

"""1.   Find mean, median, IQR for Sachin, Rahul and India.
2.   Find the histogram of Sachin's scores with 10 bins.
3.   Find the mean of Sachin's scores grouped by 25 matches.
4.   Find mean of Sachin's scores where he has scored a century.
5.   Find the mean of Sachin's scores when Rahul has scored less than 10.
6.   Find mean for Sachin's scores based on which quartile India's scores fall in.
7.   For every match find out who has scored more - Sachin or Rahul.
8.   How many more runs does Sachin's scores on average after having scored X runs.
9.   How many matches did Sachin take to score first 1000 runs, next 1000 runs,..............

Problem 1
"""

import numpy as np

cric_data = np.loadtxt("cric_data.tsv",
                       skiprows=1)

cric_data

cric_data.shape

# Now deleting the first row
cric_data = cric_data[:, [1, 2, 3]]

cric_data.shape

sachin = cric_data[:, 0]

rahul = cric_data[:, 1 ]

india = cric_data[:, 2]

def stats(col):
    print('Mean ',np.mean(col))
    print('Meadian',np.median(col))
    print('IQR',np.percentile(col,75) - np.percentile(col,25))

stats(sachin)

stats(rahul)

stats(india)

# Other ways to compute..........
np.mean(cric_data, axis=0)

np.median(cric_data, axis=0)

np.percentile(cric_data, 75, axis=0) - np.percentile(cric_data, 25, axis=0)

"""Problem - 2"""

np.histogram(sachin)

"""Problem - 3"""

sachin.shape

sachin.reshape(9, 25).shape

sachin_by_25s = sachin.reshape(9,25)

#prints the mean of 25 matches of batch, of 225 total matches...
np.mean(sachin_by_25s, axis=1)

"""Problem 4, 5"""

# To ckeck where the sachin have scored a century.......
sachin >= 100
#prints all the values with or without century of sachin....

#prints 125 means when ever he scores century, then avarage is 125..
np.mean(sachin[sachin >= 100])

np.mean(sachin[rahul <= 10])

"""Problem - 6"""

qrs = np.percentile(india,[25, 50, 75, 100])

"""If India <= 175: Sachin's average is.....
 If India <=216: Sachin's average is.....  <=273 <=499
 If 0 <= India < 175: Sachin's average is .....
 If 175 <= India < 216: Sachin's average is .....
"""

india < qrs

india.shape

qrs.shape

qrs = qrs.reshape(4,1)

indices = india<qrs

indices.shape

sachin[indices[0,:]]

sachin[indices[1,1]]

for i in range (4):
    print(i, np.mean(sachin[indices[i]]))

"""Problem-7"""

snr = cric_data[:, 0:2]

#argmax -> returns the index, where largest number is present....
np.argmax(snr, axis = 1)
# 0 -> sachin scored more ......
# 1 -> means rahul has scored more .........

is_rahul_higher = np.argmax(snr, axis = 1)

#what faction of matches does rahul scored more .........
p.sum (is_rahul_higher)/225

#Show name of player who have scored more in 225 matches....
np.where(is_rahul_higher == 0, 'Sachin', 'Rahul')

"""Problem-8"""

x_arr = np.arange(0,101,5)

x_arr = x_arr.reshape(x_arr.shape[0], 1)

sachin >= x_arr

indices = (sachin >= x_arr)

indices.shape

sachin[indices[1,:]]

for i in range(x_arr.shape[0]):
    print(x_arr[i,0],
          np.mean(sachin[indices[i,:]]) - x_arr[i,0])

"""Problem- 9"""

sachin

np.cumsum(sachin)
#100 -> first match run.....
#111 -> run scored in first 2 matches.......
#119 -> run scored in first 3 matches.........   so on...

sachin_cumscores = np.cumsum(sachin)

np.histogram (sachin_cumscores, bins = np.arange(0, 10000, 1000))

"""#Practise Exercise"""

import numpy as np

a = np.array([1,2,3,4])
a[0] = 0.9
print(a[0], a.dtype)

import numpy as np

a = np.array([1.0, 2.2, 3.5])
a = a/0.0
print(a[0])

import numpy as np

a = np.arange(10)
b = np.where(a % 2 == 1, 1, a)
print(b)

import numpy as np

a = np.arange(3)
b = a.reshape(2,2)
print(b)

import numpy as np

a = np.array([3,6,9,12,15])
b = np.array([2,4,6,8,12])
c = np.where(a == b)
print(c[0])

import numpy as np

a = np.array([1,2,3,4,5])
print(a[::-1])

import numpy as np
a = np.array([1,2,3,4,5])
print(a[2:None])

import numpy as np

a = np.array([[1,2,3], [4,5,6]])
print(a[1][2])

import numpy as np

a = np.arange(10)
b = np.where(a %2 == 1, 1, a)
print(b)

"""#Pandas"""

import numpy as np
import pandas as pd

"""Creating Series objects..."""

s = pd.Series([0,1,1,2,3,5,8])

print(s)

s.values

s.index

for v in s.values:
    print(v)

for v in s.index:
    print(v)

#zipping helps us to get the tupple's .....
for item in zip(s.index, s.values):
    print(item)

s[0]

s[1]

s[5]

mars = pd.Series([0.33, 57.9, 4222.6], index=['mass', 'diameter', 'dayLength'])

print(mars)

mars['mass']

arr = np.random.randint(0, 10, 10)

arr

ind = np.arange(10, 20)

rand_series = pd.Series(arr, index=ind)

print(rand_series)

"""Creating series form deictionary"""

d = {}
d['mass'] = 0.33
d['diameter'] = 56.9
d['dayLength'] = 4222.6

print(d)

mars = pd.Series(d)

print(mars)

"""Adding to series or updation"""

mars = pd.Series(d, index=['mass','diameter'])

print(mars)

"""#iloc and loc"""

s =pd.Series([0.0, 1, 1, 2, 3, 5, 8], index=[1,2,3,4,5,6,7])

print(s)

# loc gives the value at index defined.....
s.loc[4]

#iloc is value for the implecit location...
s.iloc[3]

mercury = pd.Series(d, index=['mass', 'diameter', 'dayLength'])

mercury.loc['mass']

mercury.iloc[0]

mercury.iloc[-1]

#slicing can also be done using iloc......
mercury.iloc[0:2]

mercury.loc['mass':'dayLength']

"""#Operation with Series..."""

mass = pd.Series([0.33, 4.87, 1898, 86.8, 102, 0.0146],
                  index=['Mercury', 'Venus', 'Earth', 'Mars ', 'Jupiter', 'Saturn'])

print(mass)

#bad practice
mass[1]

#godd practice
mass.iloc[1]

mass.loc['Earth']

mass >= 100

mass[(mass > 100) & (mass < 600)]

mass

np.mean(mass)

np.amin(mass)

np.amax(mass)

np.median(mass)

np.var(mass)

mass+mass  #doubles the mass of planets........

bigMass = mass[mass>100]

print(bigMass)

newMass = (bigMass - mass)

#NaN means not a number...............
print(newMass)

newMassAdd =(bigMass+mass)

print(newMassAdd)

pd.isnull(newMass)

newMass[~pd.isnull(newMass)]

mass

#replacing mass with moon...........
mass['Moon'] = 0.7346

mass

"""#Collect numbers for the diameter of these planets (heavnly bodies) and store it as a series object. Then given these two series objects mass and diameter, computer the density of each planet..."""

diameter = pd.Series ([4879, 12104, 12104, 3475, 6792, 142984, 120536, 51118, 49528],
                      index=['Mercury', 'Venus', 'Earth', 'Moon', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune'])

#Created series objects.....
density = pd.Series([])

print(density)

mass

diameter

for planet in mass.index:
    density[planet] = mass[planet]/(np.pi*diameter[planet] * diameter[planet] * diameter[planet] / 6)

print(density)

density = mass / (np.pi * np.power(diameter, 3)/6)

print(density)

mass['PlanetX'] = 6

density = mass / (np.pi * np.power(diameter, 3)/6)

density

"""#Task - 2 .
Given this density series, replace all values which NaNs with the mean density of all planets....

#Task - 3

Compare Dictionary with Series..

1.   checking if someone key is present.
2.    summing values..
3.    computing std.....
"""

#more efficeint way to compute the density of planets....
density[pd.isnull(density)] = np.mean(density)

print(density)

# firstly initializing the words into dictionary.....
myDictionary = {1: 1, 2:2}
n = 10000
for i in range(n):
    myDictionary = i % 10

import pandas as np

mySeries = pd.Series(myDictionary)

# now checking if the particular key is present or not...
# for all values..........

m = 10000

array = np.random.randint(0, n, m)

#%%timeit
for i in array:
    i in myDictionary

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# for i in array:
#     i in mySeries

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# sum(myDictionary.values())

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# np.sum(mySeries)

# Commented out IPython magic to ensure Python compatibility.
# ##computing standard deviation ......
# %%timeit
# mean = sum(myDictioanry.values()) / N
# variance = sum ([(x-mean)**2) for x in myDictionary.valuse()])

"""#Nifty Case Study>>>>"""

import pandas as pd

nifty = pd.read_csv('nifty.csv', index_col=0).iloc[:, 0]

print(nifty)

# head -> is used for storing upto how much values we want to
# iterate and store or print the data..........
nifty.head(20)

# tail -> for buttom numbers .......
nifty.tail(20)

import numpy as np

# mean
np.mean(nifty)

np.median(nifty)

np.std(nifty)

"""#Problem 1
What fraction of days did the market close higher than the previous day's close............
"""

nifty[2]

nifty[4]

nifty[4] - nifty[2]

# prints the elements of data from second rows..
# means it will not print first row data.....
nifty[1:]

#here it will print all data, except last data......
nifty[:-1]

#here, nothing is printed because the code is running in rorking of
# series not numpy.....
# to get the output we while subtracting first we have to align the
#indices to get the output for subtraction in series......
nifty[1:] - nifty[:-1]

nifty[:-1] - nifty[1:]

nifty[1:]+nifty[:-1]

#For printing the subtracted output in series working
#we have to use values function for function operation....

nifty.values[1:] - nifty.values[:-1]

#Now adding the values for couting the values sum...
# firstly, we have to compare the value....
# secondly, we have to sum uo the compared values....

(nifty.values[1:] - nifty.values[:-1]) > 0
# prints the boolean number of greater values...

np.sum(nifty.values[1:] - nifty.values[:-1])>0

np.sum((nifty.values[1:] - nifty.values[:-1]) > 0)

# now finding the length of total holidays in the FY....
np.sum((nifty.values[1:] - nifty.values[:-1]) > 0 ) / len(nifty)

"""# Problems

1.   Compute moving average of the last 5 days.
2.   Subset the data to include only data for fridays...


"""

import pandas as pd

nifty = pd.read_csv('nifty.csv', index_col=0).iloc[:, 0]

print(nifty)

nifty.index[0]

d = pd.Timestamp(nifty.index[0])

d.dayofweek



"""#Pandas Continued

DataFrames
"""

import numpy as np
import pandas as pd

"""Creating Dataframe objects

Dataframe is used to collect a data in one set and use it when required.....
"""

arr = np.random.randint(0,10,(5,3))

arr

//creating dataframe
df = pd.DataFrame(arr)

df

df.values

df.index

df.columns

for c in df.columns:
    print(c)

df.values[0]

df.index = ['R1', 'R2', 'R3', 'R4', 'R5']
df.columns = ['C1', 'C2', 'C3']

df

df.loc['R3', 'C2']

type(df.iloc[2:4, 1:3])

df.loc['R3':'R5', 'C2':'C3']

df = pd.DataFrame(arr)

df

df.values

"""Dataframe is collection of series objects."""

df.iloc[0]

df.iloc[:, 0]

df.shape

df.T

"""Task on creating a dataframe"""

def create_df(nRows, nCols, maxRand=10):
    arr = np.random.randint(0, maxRand, (nRows, nCols))
    df = pd.DataFrame(arr)
    df.index = ['R' + str(x) for x in np.arange(1, nRows+1) ]
    df.columns = ['C' + str(x) for x in np.arange(1, nCols+1)]
    return df

create_df(5, 3)

create_df(2,5)

mass = pd.Series([0.33, 4.87, 1898, 86.8, 102, 0.0146],
                  index=['Mercury', 'Venus', 'Earth', 'Mars ', 'Jupiter', 'Saturn'])

diameter = pd.Series ([4879, 12104, 12104, 3475, 6792, 142984, 120536, 51118, 49528],
                      index=['Mercury', 'Venus', 'Earth', 'Moon', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune'])

mass

diameter

df = pd.DataFrame({'mass':mass, 'diameter':diameter})

df

"""creating new column"""

df['pop'] = 0

df

df['pop']['Earth'] = 8000000

df

df['mass'] is df.mass

"""creating new row"""

df.loc['Col_Mean'] = 0

df

np.mean(df['mass'])

"""delete a column"""

df.drop('Col_Mean', inplace = True)

df.drop('pop', axis=1, inplace = True)

df

np.mean(df['mass'])

df.loc['col_mean'] = [np.mean(df['mass']), np.mean(df['diameter'])]

df

def create_mean_row(df):
    df.loc['col_mean'] = [np.mean(df[col]) for col in df.columns]
    return df

df

df.drop('col_mean')

create_mean_row(df)

"""alternate way"""

def create_mean_row(df):
    df.loc['col_mean'] = df.mean()
    return df

df

df = create_df(5,3)

##computes the mean column wise......
df.mean()

# returns the all possible row name...
df.mean(axis=1)

df

df['Row_Mean'] = df.mean(axis=1)

df.loc['Col_Mean'] = df.mean()

df

df.median()

df.min()

df.max()

df.quantile(0.50)

df.drop('Row_Mean', axis =1)

# describe will compute all thinsgs and combine it...
df.describe()

"""Seaborn library for planets...."""

import seaborn as sns

df = sns.load_dataset('planets')

df.info()

df.head()

df.tail()

df.describe()

"""Go through each row of the dataframe and delete it (drop it), if any column is null"""

for r in df.index:
    for c in df.columns:
        if pd.isnull(df.loc[r,c]):
            df.drop(r, inplace=True)
            break

df.describe()

#other way....

for i, r in df.iterrows():
    print (i)
    print (r)
    break

for i, r in df.iterrows():
    print(pd.isnull(r).any())
    df.drop(i, inplace=True)

df.describe()

#single command

df.dropna(inplace=True)

df.describe()

"""#Task 2 -Filtering data......
Filter and show only those rows, which are have planets that are found in the 2010s and method is 'Radial Velocity' and 'Transit' and distance is large (> 75 percentile)
"""

df_ = df.copy()
per_75 = df.distance.quantile(0.75)
for i, r in df_.iterrows():
    if r['year'] < 2010:
        df_.drop(i, inplace=True)
        continue
    if r['method'] != 'Radial Velocity' and r['method'] != 'Transit':
        df.drop(i, inplace=True)
        continue
    if r['distance'] < per_75:
        df_.drop(i, inplace=True)
        continue

df.describe()

per_75

df_ = df.copy()
df_ = df_[
    (df_ ['year'] >= 2010) &
    ((df_['method'] == 'Radial Velocity') | (df_['method'] == 'Transit')) &
    (df_['distance'] > per_75)
]

df_.describe()

"""#Task - 3 Manipulating the data..
Modify the method column to have only the abbreviation of each method.........
"""

df.method.unique()

s = 'Radial Velocity'

''.join([x[0] for x in s.split()])

short_names = {}
for s in df.method.unique():
    short_names[s] = ''.join([x[0] for x in s.split(' ')])

print(short_names)

for i, r in df.iterrows():
    df.loc[i, 'short_method'] = short_names.get(r['method'], r['method'])

df.head()

df.tail()

# More efficient way of doing .........
df = sns.load_dataset('planets')

def shorten_method(s):
    return short_names.get(s,s)

df['short_method'] = df['method'].apply(shorten_method)

df.head()

"""Task 4
Count the number of planets discovered for each method type.....

"""

# Split the data into smaller chunks...
# Apply some fun. in each smaller chunk ...
# Aggregate the results from each chunk together ..

for m in df.method.unique():
    print(m)
    print(df[df.method == m].count())

d = {}
for m in df.method.unique():
    d[m] = df[df.method == m]['method'].count()
print(d)

# Now by using pandas ......
df.groupby('method')['method'].count()

df.groupby('method')['distance'].mean()

"""Task 5 - What fraction of planets have been found in last decade....

1. Filter the data for given condition (in this case planets found in last decade).
2. Split (in this case across method).
3. Apply (in this case just count).
4. Aggregate (to represent the final result)....
"""

df[df.year >= 2010]

df[df.year >= 2010].groupby('method')['method'].count()

s_2010s = df[df.year >= 2010].groupby('method')['method'].count()

s_allTime = df.groupby('method')['method'].count()

s_2010s/s_allTime

"""Find dataset of Nifty numbers from 2018  and 2019 - daily numbers open, close, high, low..."""

nifty50_2018 = pd.read_csv('NIFTY50_2018.csv')

nifty50_2018.head()

nifty50_2018 = pd.read_csv('NIFTY50_2018.csv', index_col=0)

nifty50_2018.head()

nifty50_2018.loc['31 Dec 2018']

nifty50_2018['Open']

nifty50_2019 = pd.read_csv('NIFTY50_2019.csv', index_col=0)

nifty50_2019.head()

pd.concat([nifty50_2018, nifty50_2019])

nifty50 = pd.concat([nifty50_2018, nifty50_2019])

nifty50.shape

"""#Assignments Problems"""

import pandas as pd
data = [['A', 10], ['B', 15], ['C', 14], ['D', 14], ['F', 10], ['G', 11], ['E', 12]]
df = pd.DataFrame(data, columns = ['Name', 'Age'])
grp = df.groupby("Age")
for g in grp:
    print(type(g[1]))
    break

import pandas as pd
data = [['A', 10], ['B', 15], ['C',14], ['D',14], ['E',12], ['F', 10], ['G',11]]
df = pd.DataFrame(data, index = [ 'a','b','c','d','e','f','g'], columns = ['Name', 'Age'])
print(df['a']['Age'])
break

